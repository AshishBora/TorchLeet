# TorchLeet

TorchLeet is a curated set of PyTorch practice problems, inspired by LeetCode-style challenges, designed to enhance your skills in deep learning and PyTorch.

**What's cool? ðŸš€**
- **Diverse Questions**: Covers beginner to advanced PyTorch concepts (e.g., tensors, autograd, CNNs, GANs, and more).
- **Guided Learning**: Includes incomplete code blocks (`...` and `#TODO`) for hands-on practice along with Answers

## Getting Started

### 1. Install Dependencies
- Install pytorch: [Install pytorch locally](https://pytorch.org/get-started/locally/)
- Some problems need other packages. Install as needed.

### 2. Structure
- `<E/M/H><ID>/`: Easy/Medium/Hard along with the question ID.
- `<E/M/H><ID>/qname.ipynb`: The question file with incomplete code blocks.
- `<E/M/H><ID>/qname_SOLN.ipynb`: The corresponding solution file.

### 3. How to Use
- Navigate to questions/ and pick a problem
- Fill in the missing code blocks `(...)` and address the `#TODO` comments.
- Test your solution and compare it with the corresponding file in `solutions/`.

**Happy Learning! ðŸš€**

## Question Set

### ðŸŸ¢Easy
1. [Implement linear regression](https://github.com/Exorust/TorchLeet/blob/main/e1/lin-regression.ipynb) [(Solution)](https://github.com/Exorust/TorchLeet/blob/main/e1/lin-regression_SOLN.ipynb)
2. [Write a custom Dataset and Dataloader for a CSV file](https://github.com/Exorust/TorchLeet/blob/main/e2/custom-dataset.ipynb) [(Solution)](https://github.com/Exorust/TorchLeet/blob/main/e2/custom-dataset_SOLN.ipynb) 
3. Write a custom activation function  
4. Write a custom Loss function (Huber Loss)  
5. Zero-out gradients in PyTorch  
6. Run TensorBoard with PyTorch  
7. Save and load your model for later  

### ðŸŸ¡Medium
8. Implement a Deep Neural Network  
9. Implement an LSTM  
10. Implement a CNN on CIFAR-10  
11. Implement an RNN  
12. Use `torchvision.transforms` to apply data augmentation  
13. Add a benchmark to your PyTorch code  
14. Train an autoencoder for anomaly detection  

### ðŸ”´Hard
15. Write a custom Autograd function  
16. Write a Neural Style Transfer  
17. Write a Transformer  
18. Write a GAN  
19. Write Sequence-to-Sequence with Attention  
20. Quantize your language model
21. Enable distributed training in pytorch (DistributedDataParallel)
22. Work with Sparse Tensors
23. Implement Mixed Precision Training using torch.cuda.amp
24. Add GradCam/SHAP to explain the model.


# Contribution
Feel free to contribute by adding new questions or improving existing ones. Ensure that new problems are well-documented and follow the project structure.

# Authors:

<div align="center">
  <table>
    <tr>
      <td align="center">
        <a href="https://github.com/Exorust">
          <img src="https://avatars.githubusercontent.com/u/20578676?v=4" width="100px;" alt="Chandrahas Aroori"/>
          <br />
          <b>Chandrahas Aroori</b>
        </a>
        <br />
        ðŸ’» Developer
      </td>
      <td align="center">
        <a href="https://github.com/author2">
          <img src="https://avatars.githubusercontent.com/u/7891011?v=4" width="100px;" alt="Author 2"/>
          <br />
          <b>Caslow</b>
        </a>
        <br />
        ðŸ’» Developer
      </td>
    </tr>
  </table>
</div>
