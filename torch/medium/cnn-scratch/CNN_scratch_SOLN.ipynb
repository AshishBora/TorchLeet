{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Implement a CNN for CIFAR-10 (With Custom Layers)\n",
    "\n",
    "### Problem Statement\n",
    "You are tasked with implementing a **Convolutional Neural Network (CNN)** for image classification on the **CIFAR-10** dataset using PyTorch. However, instead of using PyTorch's built-in `nn.Conv2d` and `nn.MaxPool2d`, you must implement these layers **from scratch** using `nn.Module`. Your model will include convolutional layers for feature extraction, pooling layers for downsampling, and fully connected layers for classification.\n",
    "\n",
    "### Requirements\n",
    "1. **Implement Custom Layers**:\n",
    "   - Create a custom `Conv2dCustom` class that mimics the behavior of `nn.Conv2d`.\n",
    "   - Create a custom `MaxPool2dCustom` class that mimics the behavior of `nn.MaxPool2d`.\n",
    "\n",
    "2. **Define the CNN Model**:\n",
    "   - Use `Conv2dCustom` for convolutional layers.\n",
    "   - Use `MaxPool2dCustom` for pooling layers.\n",
    "   - Use standard `nn.Linear` for fully connected layers.\n",
    "   - The model should process input images of shape `(3, 32, 32)` as in the CIFAR-10 dataset.\n",
    "\n",
    "### Constraints\n",
    "- You must not use `nn.Conv2d` or `nn.MaxPool2d`. Use your own custom implementations.\n",
    "- The CNN should include multiple convolutional and pooling layers, followed by fully connected layers.\n",
    "- Ensure the model outputs class predictions for **10 classes**, as required by CIFAR-10.\n",
    "\n",
    "<details>\n",
    "  <summary>ðŸ’¡ Hint</summary>\n",
    "  Define `Conv2dCustom` and `MaxPool2dCustom` as subclasses of `nn.Module`. Use nested loops and tensor slicing to perform the operations.  \n",
    "  In `CNNModel.__init__`, use these custom layers to build the architecture.  \n",
    "  Implement the forward pass to pass inputs through convolution, activation, pooling, flattening, and fully connected layers.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcf56f0d6f941e48bd710768cad07e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dCustom(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(Conv2dCustom, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.weight = nn.Parameter(torch.randn(out_channels, in_channels, *self.kernel_size) * 0.1)\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, in_channels, H, W = x.shape\n",
    "        KH, KW = self.kernel_size\n",
    "        SH = SW = self.stride\n",
    "        PH = PW = self.padding\n",
    "\n",
    "        x_padded = F.pad(x, (PW, PW, PH, PH))\n",
    "\n",
    "        OH = (H + 2 * PH - KH) // SH + 1\n",
    "        OW = (W + 2 * PW - KW) // SW + 1\n",
    "\n",
    "        out = torch.zeros((batch_size, self.out_channels, OH, OW), device=x.device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for oc in range(self.out_channels):\n",
    "                for i in range(OH):\n",
    "                    for j in range(OW):\n",
    "                        h_start = i * SH\n",
    "                        h_end = h_start + KH\n",
    "                        w_start = j * SW\n",
    "                        w_end = w_start + KW\n",
    "                        region = x_padded[b, :, h_start:h_end, w_start:w_end]\n",
    "                        out[b, oc, i, j] = torch.sum(region * self.weight[oc]) + self.bias[oc]\n",
    "        return out\n",
    "\n",
    "class MaxPool2dCustom(nn.Module):\n",
    "    def __init__(self, kernel_size, stride=None):\n",
    "        super(MaxPool2dCustom, self).__init__()\n",
    "        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.stride = stride if stride is not None else kernel_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, H, W = x.shape\n",
    "        KH, KW = self.kernel_size\n",
    "        SH = SW = self.stride\n",
    "\n",
    "        OH = (H - KH) // SH + 1\n",
    "        OW = (W - KW) // SW + 1\n",
    "\n",
    "        out = torch.zeros((batch_size, channels, OH, OW), device=x.device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for c in range(channels):\n",
    "                for i in range(OH):\n",
    "                    for j in range(OW):\n",
    "                        h_start = i * SH\n",
    "                        h_end = h_start + KH\n",
    "                        w_start = j * SW\n",
    "                        w_end = w_start + KW\n",
    "                        region = x[b, c, h_start:h_end, w_start:w_end]\n",
    "                        out[b, c, i, j] = torch.max(region)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Output: 32x32x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Output: 64x32x32\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: 64x16x16\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.4057\n",
      "Epoch [2/10], Loss: 0.9852\n",
      "Epoch [3/10], Loss: 0.2743\n",
      "Epoch [4/10], Loss: 0.9068\n",
      "Epoch [5/10], Loss: 0.2459\n",
      "Epoch [6/10], Loss: 0.4891\n",
      "Epoch [7/10], Loss: 0.0719\n",
      "Epoch [8/10], Loss: 0.1010\n",
      "Epoch [9/10], Loss: 0.0075\n",
      "Epoch [10/10], Loss: 0.1189\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 67.59%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
