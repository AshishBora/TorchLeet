{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61a94f9",
   "metadata": {},
   "source": [
    "# Problem: Write AlexNet from Scratch\n",
    "\n",
    "### Problem Statement\n",
    "Implement the **AlexNet architecture** in PyTorch by completing the required sections. The model should include convolutional layers, ReLU activations, pooling layers, and fully connected layers to process image data for classification tasks.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "1. **Define the AlexNet Architecture**:\n",
    "   - **Feature Extractor (Convolutional Base)**:\n",
    "     - Stack convolutional layers with appropriate kernel sizes, strides, and paddings.\n",
    "     - Use `nn.ReLU` as the activation function after each convolution.\n",
    "     - Apply `nn.MaxPool2d` after selected layers to reduce spatial dimensions.\n",
    "   - **Classifier (Fully Connected Layers)**:\n",
    "     - Flatten the output from the convolutional base.\n",
    "     - Add fully connected layers with ReLU activations and dropout for regularization.\n",
    "     - End with a final linear layer projecting to the number of output classes.\n",
    "\n",
    "2. **Implement the Forward Method**:\n",
    "   - Pass the input image through the convolutional base.\n",
    "   - Flatten the feature map output to a vector.\n",
    "   - Pass it through the fully connected classifier to produce final predictions.\n",
    "\n",
    "3. **Weight Initialization**:\n",
    "   - Initialize weights of convolutional and linear layers using a normal distribution.\n",
    "   - Set biases to zero.\n",
    "\n",
    "### Constraints\n",
    "- Assume input images are RGB with shape **(3, 224, 224)**.\n",
    "- Ensure the model is compatible with **batch processing**.\n",
    "- The final layer output size should match the number of target classes (e.g., 10 for CIFAR-10).\n",
    "- Avoid using any pretrained models or high-level wrappers like `torchvision.models`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc691770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize to AlexNet input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                         download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AlexNet\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):  # Adjusted for CIFAR-10\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AlexNet(num_classes=10).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ed911",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss:.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
